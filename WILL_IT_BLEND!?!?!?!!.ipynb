{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will It Blend? Deploying BlenderBot\n",
    "\n",
    "First, load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:55:46 | \u001b[33mOverriding opt[\"model\"] to internal:cgen (previously: projects.anti_scaling.distillation:DistillTransformerAgent)\u001b[0m\n",
      "03:55:46 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
      "03:55:46 | \u001b[33mOverriding opt[\"inference\"] to delayedbeam (previously: beam)\u001b[0m\n",
      "03:55:46 | \u001b[33mOverriding opt[\"beam_delay\"] to 25 (previously: 30)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:parlai_internal.agents.cgen.cgen:Initializing a Conditional GENeration (CGEN) Agent (like transformer/generator).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:55:46 | Using CUDA\n",
      "03:55:46 | loading dictionary from blender_distilled/blender_distilled.pth.checkpoint.dict\n",
      "03:55:46 | num words = 8008\n",
      "03:56:03 | Total parameters: 1,122,675,200 (1,122,019,840 trainable)\n",
      "03:56:03 | Loading existing model params from blender_distilled/blender_distilled.pth.checkpoint\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from parlai.core.agents import create_agent_from_model_file\n",
    "blender_agent = create_agent_from_model_file(\"blender_distilled/blender_distilled.pth.checkpoint\",\n",
    "                                            opt_overrides={\n",
    "                                                \"model\": \"internal:cgen\",\n",
    "                                                \"skip_generation\": False,\n",
    "                                                \"inference\": \"delayedbeam\",\n",
    "                                                \"beam_delay\": 25\n",
    "                                            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_agent.opt[\"temperature\"] = 0.7\n",
    "blender_agent.opt[\"topp\"] = 0.9\n",
    "blender_agent.opt[\"topk\"] = 5\n",
    "blender_agent.opt[\"beam_min_length\"] = 15\n",
    "blender_agent.opt[\"beam_size\"] = 10\n",
    "blender_agent.opt[\"inference\"] = \"beam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender_agent.opt[\"beam_context_block_ngram\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Minimal example from Github issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user utterance: \n",
      "Added bot utterance: Hi, this is an Alexa Prize Socialbot. I'd like to get to know you a bit better before we chat! Is it all right if I ask for you name?\n",
      "Added user utterance: trenton\n",
      "Added bot utterance: Nice to meet you, trenton! I'm looking forward to chatting with you today. So, I think the key to a good mood is eating well. What's a food that always makes you feel good?hazelnut\n",
      "Added user utterance: I love hazelnut as well! It's nice and crunchy and I especially love it as a topping on my frozen yogurt. What do you like about hazelnut?\n",
      "Added bot utterance: um i guess it tastes good\n",
      "BlenderBot replied in 703ms: I love hazelnut! It's nice as it's one of the most widely consumed foods in the world. What about you?\n",
      "All beams: I love hazelnut! It's nice as it's one of the most widely consumed foods in the world. What about you?\n",
      "I love hazelnut! It's nice as it's one of the most widely consumed foods in the world!\n",
      "I love hazelnut! It's nice as it's one of the most widely consumed fruits in the world!\n",
      "I love hazelnut! It's nice as it's one of the most widely consumed foods in the world.\n",
      "I love hazelnut! It's nice as it's one of the most widely consumed fruits in the world.\n",
      "I love hazelnut! It's nice as it's one of the most widely consumed foods in the world. Do you like it?\n",
      "I love hazelnut! It's nice as it's one of the most popular foods in the world!\n",
      "I love hazelnut! It's nice as it's one of the most common foods in the world!\n",
      "I love hazelnut! It's nice as it's one of the most widely used foods in the world!\n",
      "I love hazelnut! It's nice as it's one of the most widely consumed foods in the world\n",
      "\n",
      "BlenderBot's history view:\n",
      "  Hi, this is an Alexa Prize Socialbot. I'd like to get to know you a bit better before we chat! Is it all right if I ask for you name?  trenton  Nice to meet you, trenton! I'm looking forward to chatting with you today. So, I think the key to a good mood is eating well. What's a food that always makes you feel good?hazelnut  I love hazelnut as well! It's nice and crunchy and I especially love it as a topping on my frozen yogurt. What do you like about hazelnut?  um i guess it tastes good\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import zip_longest\n",
    "import time\n",
    "from parlai.utils.strings import normalize_reply\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "blender_agent.reset()\n",
    "\n",
    "history = [\n",
    "    \"\",\n",
    "    \"Hi, this is an Alexa Prize Socialbot. I'd like to get to know you a bit better before we chat! Is it all right if I ask for you name?\",\n",
    "    \"trenton\",\n",
    "    \"Nice to meet you, trenton! I'm looking forward to chatting with you today. So, I think the key to a good mood is eating well. What's a food that always makes you feel good?\"\n",
    "    \"hazelnut\",\n",
    "    \"I love hazelnut as well! It's nice and crunchy and I especially love it as a topping on my frozen yogurt. What do you like about hazelnut?\",\n",
    "    \"um i guess it tastes good\"\n",
    "]\n",
    "prefix = \"I love hazelnut! It's nice as\"\n",
    "def process(history):\n",
    "    pairs = zip_longest(*[iter(history)]*2)\n",
    "\n",
    "    for user, bot in pairs:\n",
    "        blender_agent.observe({'text': user, 'episode_done': False})\n",
    "        print(\"Added user utterance:\", user)\n",
    "        if bot:\n",
    "            blender_agent.history.add_reply(bot)\n",
    "            print(\"Added bot utterance:\", bot)\n",
    "    response = blender_agent.act(prefix_text=prefix)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"BlenderBot replied in {elapsed * 1000:.0f}ms: {normalize_reply(response['text'])}\")\n",
    "    print(\"All beams:\", \"\\n\".join([t for t, s in response[\"beam_texts\"]]))\n",
    "    print()\n",
    "\n",
    "    print(\"BlenderBot's history view:\")\n",
    "    print(blender_agent.history)\n",
    "    return response\n",
    "    \n",
    "response = process(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Cgen',\n",
       " 'episode_done': False,\n",
       " 'text': \"I love hazelnut! It's nice as it's one of the most widely consumed foods in the world. What about you?\",\n",
       " 'beam_texts': [(\"I love hazelnut! It's nice as it's one of the most widely consumed foods in the world. What about you?\",\n",
       "   -11.454596519470215),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely consumed foods in the world!\",\n",
       "   -11.625725746154785),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely consumed fruits in the world!\",\n",
       "   -11.740839958190918),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely consumed foods in the world.\",\n",
       "   -11.787345886230469),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely consumed fruits in the world.\",\n",
       "   -11.881574630737305),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely consumed foods in the world. Do you like it?\",\n",
       "   -11.947830200195312),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most popular foods in the world!\",\n",
       "   -12.203518867492676),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most common foods in the world!\",\n",
       "   -12.219606399536133),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely used foods in the world!\",\n",
       "   -12.322351455688477),\n",
       "  (\"I love hazelnut! It's nice as it's one of the most widely consumed foods in the world\",\n",
       "   -12.341556549072266)]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi, where are you from', \"i'm from the states! i'm from california originally but i live in utah now.\"), ('cool, i am also from utah', \"that's great, what is your favorite place?\"), ('um maybe taiwan?', None)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "history = [\n",
    "    \"hi, where are you from\",\n",
    "    \"i'm from the states! i'm from california originally but i live in utah now.\",\n",
    "    \"cool, i am also from utah\",\n",
    "    \"that's great, what is your favorite place?\",\n",
    "    \"um maybe taiwan?\"\n",
    "]\n",
    "pairs = zip_longest(*[iter(history)]*2)\n",
    "print(list(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parlai.agents.transformer.transformer import TransformerGeneratorAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
